{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#General libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Data cleanup\nimport re\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\n\n#Misc\nfrom datetime import datetime\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Part 1. Data exploration and processing"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Anime dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"anime = pd.read_csv('../input/anime_cleaned.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(anime.shape)\nprint(anime.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime.drop(['title_english', #tfdf later\n            'title_japanese', #use later\n            'title_synonyms', #use later\n            'image_url', #scrape the images and use later\n            'status', #bool column 'airing'\n            'aired_string', #same info as 'aired'\n            'aired', #use only 'aired_from_year' to calcualte 'age' of series\n            'duration', #cleaner version avaiable as duration_min\n            'rank', #use later, has missing values\n            'background', #use later - even better scrape synopses and do text analysis\n            'premiered', #cleaner version as 'aired_from_year'\n            'broadcast', #use later\n            'opening_theme', #use later\n            'ending_theme',  #use later\n            'related', #use later\n            'licensor', #use later, has ~20% missing\n            'opening_theme', #use later - parse out the artist\n            'ending_theme' #use later\n            \n           ], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean up category rating to extract category\ndef getRating(st):\n    try:\n        return st.split(\" - \")[0]\n    except:\n        return np.nan\n\nanime['rating_clean'] = anime['rating'].apply(lambda st: getRating(st))\nanime.drop(['rating'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anime.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Producer - add bool column for multiple producers and add column for each\ndef isMultProducer(st):\n    try:\n        return 1 if ',' in st else 0\n    except:\n        return 9999\n    \nanime['hasMultiple_producers'] = anime['producer'].apply(lambda st: isMultProducer(st))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split producer into columns\n#First clean space after commas\nanime['producer'] = anime['producer'].str.replace(\", \", \",\") \n\n#Split\nproducer_to_dummies = anime['producer'].str.get_dummies(sep=',').add_prefix('producer_')\n\n#Clean up\nfor col in producer_to_dummies:\n    if producer_to_dummies[col].astype(bool).sum(axis=0) < 50:\n        producer_to_dummies.drop(col,axis=1,inplace=True)\n\n#Add to main df\nanime = pd.concat([anime,producer_to_dummies],axis=1)\nanime.drop(['producer'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split genre into columns\ngenre_to_dummies = anime['genre'].str.get_dummies(sep=',').add_prefix('genre_')\n\n#Clean up\nfor col in genre_to_dummies:\n    if genre_to_dummies[col].astype(bool).sum(axis=0) < 50:\n        genre_to_dummies.drop(col,axis=1,inplace=True)\n\n#Add to main df\nanime = pd.concat([anime,genre_to_dummies],axis=1)\nanime.drop(['genre'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing values\nfor col in anime:\n    if True in anime[col].isna().value_counts():\n        print(f\"Column *{col}* has missing\")\n        print(anime[col].isna().value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encode categorical\nfor col in anime:\n    if anime[col].dtype == 'object' and col != 'title':\n        print(f\"Column {col} is object, performing label encoding\")\n        anime[col].fillna('9999', inplace=True)\n        le = LabelEncoder()\n        le.fit(anime[col])\n        anime[col] = le.transform(anime[col])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Keep a seperate df for id and title link, drop the latter from the main table [anime_id is temporarly dropped]\nanime_idTitleLink = anime[['anime_id','title']]\nanime.drop(['title', 'anime_id'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scale\nmin_max_scaler = MinMaxScaler()\nanimeFinal = pd.DataFrame(np.round(min_max_scaler.fit_transform(anime),2), columns=anime.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"animeFinal = pd.concat([animeFinal,anime_idTitleLink['anime_id'].astype(int)], axis=1)\nanimeFinal['anime_id'] = animeFinal['anime_id'].astype(int)\nanimeFinal.set_index('anime_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Final anime dataset\nprint(animeFinal.shape)\nanimeFinal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Users"},{"metadata":{"trusted":true},"cell_type":"code","source":"users = pd.read_csv('../input/users_cleaned.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(users.shape)\nprint(users.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users.drop(['username', #not needed at this time\n            'access_rank'#all missing\n           ], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean up location to split into country and city\nimport re\n\ndef getLocation(location):\n    regex = re.compile('[^a-zA-Z]')\n    try:\n        locSplit = location.split(',')\n        #print(\"Split is\", locSplit)\n        retStr = locSplit[0] if len(locSplit) == 1 else locSplit[1] \n        retStr = regex.sub('', retStr.strip().lower())\n        if len(retStr.strip()) == 0:\n            return np.nan\n        else: \n            return retStr\n    except:\n        return np.nan\n\nusers['location'] = users['location'].apply(lambda loc: getLocation(loc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#users['location'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encode location\nusers['location'].fillna('9999', inplace=True)\nle = LabelEncoder()\nle.fit(users['location'])\nusers['location'] = le.transform(users['location'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Clean up the dates to leave only a year\ndateCols = ['birth_date','join_date','last_online']\nfor col in dateCols:\n    users[col] = pd.to_datetime(users[col]).dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for missing values\nfor col in users:\n    if True in users[col].isna().value_counts():\n        print(f\"Column *{col}* has missing\")\n        print(users[col].isna().value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Label encode gender\nle = LabelEncoder()\nle.fit(users['gender'])\nusers['gender'] = le.transform(users['gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"users.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#usersAnime = pd.read_csv('../input/animelists_cleaned.csv', usecols=['username','anime_id','my_status','my_score'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#avg_anime_watched = usersAnime.groupby('username')['anime_id'].count()\n#avg_anime_watched.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nAnime: Initially 6668 cleaned up to 6132\nUsers: 108711\nUsersAnime: Mean 287, max 6536 .. :O\n\nwhat can be done:\n\nPath 1:\nwork only with 6k anime dataset to group similiar anime\nfor each user for each of their liked anime recommend similiar ones\n\nPath 2:\nfind user similiarities and make a general anime recommendation (tons of data, needs more filtering):\nFind preferred genre, type, length etc \n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Part 2: Model building"},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Content based recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors, BallTree, KDTree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdt = KDTree(animeFinal, leaf_size=30, metric='euclidean')\ndistances, indeces = kdt.query(animeFinal, k=10, return_distance=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getIdFromName(inputTitle):\n    df_found = anime_idTitleLink[anime_idTitleLink['title'].str.contains(inputTitle)]\n    exact_match = df_found[df_found[\"title\"]==inputTitle]['anime_id'].values\n    if exact_match > 0:\n        return exact_match[0]\n    else:\n        print(\"Choose Id or exact name from below\\n\", df_found)\n        return ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def printNeighbors(indeces,foundId):\n    foundIdIndex = anime_idTitleLink.loc[anime_idTitleLink['anime_id']==foundId].index[0]\n    foundIdGroup = []\n    if foundIdIndex:\n        #print(f\"For ID {foundId} corresponding row index is {foundIdIndex}\\n\")\n        for group in indeces:\n            if foundIdIndex in group:\n                foundIdGroup = group\n            \n        for val in foundIdGroup:\n            if val != foundIdIndex:\n                print(anime_idTitleLink.loc[val]['title'])\n    \n\ndef getSimiliarByName(indeces,anime_title = None, anime_id = None):\n    if anime_title:\n        anime_id = getIdFromName(anime_title)\n    print(\"Anime Id is\", anime_id)\n    if anime_id:\n        printNeighbors(indeces,anime_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"getSimiliarByName(indeces,anime_title='Bleach')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kdt.kneighbors_graph(X).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ideas:\n\"\"\"\n-Use related column to exclude parent stories\n-Scrape description/synopses\n-Add image features\n-Scrape recomendation and make a supervised learning\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}